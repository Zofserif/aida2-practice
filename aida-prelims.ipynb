{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fte_zsqVdp8R"
      },
      "source": [
        "# Topic02a : Prelim Problem Set I\n",
        "\n",
        "\n",
        "| Submitted By:               | Instructor:               |\n",
        "|-----------------------------|---------------------------|\n",
        "| Vallarta, Troy Joaquin      | Engr. Dylan Josh D. Lopez |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "e8lUABo1NPd8"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpcY5oJ5eFxA"
      },
      "source": [
        "## Case 1\n",
        "Represent the following representations into its vectorized form using LaTeX.\n",
        "\n",
        "*Problem 1.a. System of Linear Equations*\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{cases} -y+z=\\frac{1}{32} \\\\ \n",
        "            \\frac{1}{2}x -2y=0 \\\\\n",
        "            -x + \\frac{3}{7}z=\\frac{4}{5}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "**Problem 1.b. Linear Combination**\n",
        "$$\\cos{(\\theta)}\\hat{i} + \\sin{(\\theta)}\\hat{j} - \\csc{(2\\theta)}\\hat{k}$$\n",
        "**Problem 1.c. Scenario**\n",
        "\n",
        "\n",
        "A conference has 200 student attendees, 45 professionals, and has 15 members of the panel. There is a team of 40 people on the organizing committee. Represent the *percent* composition of each *attendee* type of the conference in matrix form.\n",
        "\n",
        "Express your answers in LaTeX in the answer area.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwshlVHtqcDB"
      },
      "source": [
        "**Problem 1.a. System of Linear Equations**\n",
        "\n",
        "$$\\begin{bmatrix} \n",
        "-1 \\ \\ 1 \\ -\\frac{1}{32}\\\\ \n",
        "\\frac{1}{2} \\ -\\ 2 \\ \\ 0\\\\\n",
        "-1 \\ \\frac{3}{7} -\\frac{4}{5} \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "$$ $$\n",
        "\n",
        "$$\n",
        " X + Y + Z = K \\\\\n",
        "$$\n",
        "\n",
        "**Problem 1.b. Linear Combination**\n",
        "\n",
        "$$ \\hat{I} + \\hat{J} + \\hat{K} $$\n",
        "\n",
        "**Problem 1.c. Scenario**\n",
        "\n",
        "$$\\begin{bmatrix} \n",
        "\\frac{2}{3} \\ \\frac{3}{20} \\ \\frac{1}{20}  \\ \\frac{2}{50} \n",
        "\\end{bmatrix}$$\n",
        "\n",
        "$$$$\n",
        "\n",
        "$$ T = \\frac{A}{T} + \\frac{B}{T} + \\frac{C}{T} + \\frac{D}{T}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvb1MGs9QNVt"
      },
      "source": [
        "# Case 2\n",
        "> **Problem 2.a: Vector Magnitude**\n",
        "\n",
        ">The magnitude of a vector is usually computed as:\n",
        "$$||v|| = \\sqrt{a_0^2 + a_1^2 + ... +a_n^2}$$\n",
        "Whereas $v$ is any vector and $a_k$ are its elements wherein $k$ is the size of $v$.\n",
        "Re-formulate $||v||$ as a function of an inner product. Further discuss this concept and provide your user-defined function.\n",
        "\n",
        "> **Problem 2.b: Angle Between Vectors**\n",
        "\n",
        "> Inner products can also be related to the Law of Cosines. The property suggests that:\n",
        "$$u\\cdot v = ||u||\\cdot||v||\\cos(\\theta)$$\n",
        "Whereas $u$ and $v$ are vectors that have the same sizes and $\\theta$ is the angle between $u$ and $v$.\n",
        "\n",
        "> Explain the behavior of the dot product when the two vectors are perpendicular and when they are parallel.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sALN1Moy4lKL"
      },
      "source": [
        "**Problem 2.a: Vector Magnitude**\n",
        "\n",
        "$$||v|| = \\sqrt {\\sum^n_{k=0}a_k^2}$$\n",
        "\n",
        "\n",
        "**Problem 2.b: Angle Between Vectors**\n",
        "\n",
        "Two vectors are known perpendicular when or if their dot product is equals to 0. \n",
        "\n",
        "Two vectors are known parallel when or if their dot product is equal to the product \n",
        "of magnitude of the two vectors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sgt8CnbyGSRV"
      },
      "source": [
        "\\begin{bmatrix} cos(\\theta) = \\frac{u\\cdot v}{||u||\\cdot||v||}\\end{bmatrix} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKqEv7hZKm--"
      },
      "source": [
        "If θ is the angle between vectors **u** and **v**, then"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2DnqZkhKGwb"
      },
      "source": [
        "\\begin{bmatrix} u \\cdot v = |u||v| cos(\\theta)\\end{bmatrix} \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY35pQaZhnxu"
      },
      "source": [
        "\\begin{bmatrix} 0 = u \\cdot (v - u) = u \\cdot v - u \\cdot u)\\end{bmatrix} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve_dboRgLevV"
      },
      "source": [
        "Therefore,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBRmjOkwLiRt"
      },
      "source": [
        "\\begin{bmatrix} u \\cdot v = u \\cdot u = |u|^2 = |u||v| \\frac{|u|}{|v|} = |u||v|cos(\\theta)\\end{bmatrix} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cH8JpkBj1xS"
      },
      "source": [
        "# Case 3\n",
        "For the final cases analysis we will be looking at series of equations building up a single feed-forward computation of a logistic regression. The case will not require you to learn fully what is logistic regression. \n",
        "\n",
        "$$X = \\begin{bmatrix} \n",
        "— (x^{(1)})^T— \\\\ \n",
        "— (x^{(2)})^T— \\\\\n",
        "\\vdots \\\\\n",
        "— (x^{(m)})^T— \\\\\n",
        "\\end{bmatrix} \\text{, } \n",
        "Y = \\begin{bmatrix} \n",
        "y^{(1)} \\\\ \n",
        "y^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "y^{(m)} \\\\\n",
        "\\end{bmatrix} \\text{, and } \n",
        "\\theta = \\begin{bmatrix} \n",
        "\\theta^{(1)} \\\\ \n",
        "\\theta^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "\\theta^{(m)} \\\\\n",
        "\\end{bmatrix} $$\n",
        "The dataset $X$ has $m$ entries with $n$ features while $Y$ is the vector containing the groud truths of a the entries of $X$, and $\\theta$ are the parameters or weights of the vectors. We first compute the vector product of the dataset and the parameters as:\n",
        "$$ z = x^{(i)}\\theta^{(i)} = X\\cdot \\theta\\\\_{\\text{Eq. 3.1}}$$\n",
        "We then solve for the hypothesis of the logistic regression alogrithm as:\n",
        "\n",
        "$$ h_\\theta(x) = g(z)\\\\_{\\text{Eq. 3.2}}$$\n",
        "\n",
        "Where $g$ is an acitvation function that maps the values of the hypothesis vector between a range of 0 and 1. We computed the activation as a sigmoid function:\n",
        "$$g(z) = \\frac{1}{1+e^{-z}}\\\\_{\\text{Eq. 3.3}}$$\n",
        "Finally we compute the loss of the logistic regression algorithm using $J$. Wheras $J(\\theta)$ is a function that computes the logistic loss of the hypothesis with respect to the ground truths $y$. it is then computed as:\n",
        "$$J(\\theta) = \\frac{1}{m} \\sum^m_{i=0}=[-y^{(i)}\\log({h_{\\theta}(x^{(i)})})-(1-y^{(i)})\\log(1-h_{\\theta}(x^{(i)}))]\\\\_{\\text{Eq. 3.4}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ8jJV9-qyFy"
      },
      "source": [
        "> **Problem 3.a: Matrix Equivalences**\n",
        "\n",
        "> In Eq. 1, $z$ can also be solved as $X \\cdot \\theta$ which is the vectorized form of $x^{(i)}\\theta^{(i)}$. However, it can also be expressed as $\\theta^T\\cdot X$. Prove the equality of $X \\cdot \\theta$ with $\\theta^T\\cdot X$ in this case.\n",
        "\n",
        "> **Problem 3.b: Matrix Shapes**\n",
        "\n",
        "> Determine the shape of $h_\\theta$ if $X$ has a shape of $(300,5)$.\n",
        "\n",
        "> **Problem 3.c: Vectorization**\n",
        "\n",
        "> Express $J(\\theta)$ into its vectorized form.\n",
        "\n",
        "> **Problem 4.c: Computational Programming (Also Laboratory 2)**\n",
        "\n",
        "> Encode Equations 3.1 to 3.4 as the class `LRegression` wherein:\n",
        "\n",
        "> * `LRegression` should be instantiated with a dataset $X$, a ground truth vector $y$, and a parameter vector $\\theta$. Each parameter should have a data type of `numpy.array`.\n",
        "> * It should further have `methods`reflecting to at least the four (4) aforementioned equations. Each should have a return value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4rgVsXnNaZP"
      },
      "source": [
        "**Problem 3.a: Matrix Equivalences**\n",
        "\n",
        "$$X \\cdot \\theta = \\theta^T\\cdot X$$\n",
        "\n",
        "$$\\begin{bmatrix} \n",
        "— (x^{(1)})^T \\theta— \\\\ \n",
        "— (x^{(2)})^T \\theta— \\\\\n",
        "\\vdots \\\\\n",
        "— (x^{(m)})^T \\theta— \\\\\n",
        "\\end{bmatrix} = \n",
        "\\begin{bmatrix} \n",
        "— \\theta^T (x^{(1)})- \\\\ \n",
        "— \\theta^T (x^{(2)})- \\\\ \n",
        "\\vdots \\\\\n",
        "— \\theta^T (x^{(m)})-\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Problem 3.b: Matrix Shapes**\n",
        "Given that the θ have the size of (m,1) \n",
        "Following the dot product rule, m being the shape of X therefore \n",
        "the h(θ) should be ( 300,1)\n",
        "\n",
        "**Problem 3.c: Vectorization**\n",
        "\n",
        "$$J(\\theta) = \\frac{1}{m} X^T (h_ \\theta(x) - y)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6xFVYcMUq3O"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7ebbKerIy0Rt"
      },
      "outputs": [],
      "source": [
        "class LRegression:\n",
        "  def __init__(self, datasetX, truth_vetor_y, vector):\n",
        "    self.datasetX = datasetX\n",
        "    self.truth_vector = truth_vetor_y\n",
        "    self.vector = vector\n",
        "\n",
        "  def vector_magnitude(self):\n",
        "    magn = np.linalg.norm(self.vector)\n",
        "    return magn\n",
        "\n",
        "  def vect_prod(self): # EQ 3.1\n",
        "    self.z = np.dot(self.datasetX, self.vector)\n",
        "    return self.z\n",
        "  \n",
        "  def sigmoid_function(self): #EQ 3.3\n",
        "    self.sig = 1 / (1 + np.exp(-(self.z)))\n",
        "    return self.sig\n",
        "  \n",
        "  def logistic_loss(self): #EQ 3.4\n",
        "    m = self.datasetX.shape[0]\n",
        "    answer = (1/m) * np.dot(self.datasetX.T, (self.sig - self.truth_vector))\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HOCHrv-b5vh4"
      },
      "outputs": [],
      "source": [
        "X = np.array([2,2,5,3])\n",
        "Vector = np.array([2,3,5,6])\n",
        "Y_Vector = np.array([2,2,1,3])\n",
        "Lregression_class = LRegression(X, Y_Vector, Vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDH9VDdS4W3y",
        "outputId": "11cc3f79-c0b5-4b31-92f7-40d94624a7bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8.602325267042627"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Lregression_class.vector_magnitude()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL3iXs7g4clb",
        "outputId": "9eca35a1-55e0-4217-8224-a77faf225ed1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Lregression_class.vect_prod()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIIayF5I4HlY",
        "outputId": "e7af880f-b9c2-458b-c1fc-936cb74e7a6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Lregression_class.sigmoid_function()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsPrM7MWZbzg",
        "outputId": "eb521fa0-3d09-4627-912e-59304eb4a356"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-2.5"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Lregression_class.logistic_loss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AIDA 2 EXAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['manila' 'makati' 'pasig' 'pasig' 'quezon city' 'aghanistan' 'manila'\n",
            " 'taguig']\n",
            "['makati' 'pasig' 'taguig' 'manila' 'manila' 'las pinas' 'antipolo'\n",
            " 'marikina']\n",
            "['makati', 'taguig', 'pasig', 'manila']\n",
            "['aghanistan', 'quezon city']\n",
            "['marikina', 'antipolo', 'las pinas']\n"
          ]
        }
      ],
      "source": [
        "## Draw a ven diagram representing the set for the two lists provied and compute for the following probabilities:\n",
        "\n",
        "A = np.array([\"manila\",\"makati\",\"pasig\",\"pasig\",\"quezon city\", \"aghanistan\",\"manila\",\"taguig\"])\n",
        "B = np.array([\"makati\", \"pasig\" , \"taguig\", \"manila\", \"manila\", \"las pinas\", \"antipolo\", \"marikina\"])\n",
        "\n",
        "def intersection(A,B):\n",
        "    return list(set(A) & set(B))\n",
        "\n",
        "def conditional(A,B):\n",
        "    return list(set(A) - set(B))\n",
        "\n",
        "## P(A)\n",
        "print(A)\n",
        "\n",
        "## P(B)\n",
        "print(B)\n",
        "\n",
        "## P(A intersect B)\n",
        "print(intersection(A,B))\n",
        "\n",
        "## P(A|B)\n",
        "print(conditional(A,B))\n",
        "\n",
        "## P (B|A)\n",
        "print(conditional(B,A))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Briefly discuss why the median is a more preferred statistic compared than the mean for datasets\n",
        "## Briefly discuss why the mean is a more preferred statistic compared than the median for a dataset that has a normal distribution\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "58033_PrelimPS_Henerawr.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
